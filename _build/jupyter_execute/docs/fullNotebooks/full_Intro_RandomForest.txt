import sklearn as sk
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


#get wine to a dataframe
df_diab = pd.read_csv('/content/diabetes.csv')

#take a look
df_diab


df_diab.dtypes

df_diab.isna().sum()

#count how many of each value in a column using value_conunts
df_diab.Outcome.value_counts()

500/(500+268)

print('the mean is = ',df_diab.BloodPressure.mean() ) 
print('the min is = ',df_diab.BloodPressure.min() ) 
print('the max is = ',df_diab.BloodPressure.max() ) 


sns.scatterplot(data=df_diab, x='DiabetesPedigreeFunction', y='Outcome')

sns.violinplot(data=df_diab, y='DiabetesPedigreeFunction', x='Outcome')


#split data into predictors (X) and target (y)
X = df_diab.drop('Outcome', axis=1)
y = df_diab['Outcome']

#split these data into training and testing datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)


from sklearn.ensemble import RandomForestClassifier

#1. Build the model
forest_classifier = RandomForestClassifier(n_estimators=1000, bootstrap=True, max_features=0.8,max_samples=0.8)

#2. Fit the model to the data
forest_classifier.fit(X_train, y_train)

from sklearn.tree import DecisionTreeClassifier

#1. Build the model
tree_classifier = DecisionTreeClassifier()

#2. Fit the model to the data
tree_classifier.fit(X_train, y_train)

#predictions from the forest model
y_forest_pred = forest_classifier.predict(X_test)

#predictions from the tree model
y_tree_pred = tree_classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_forest = confusion_matrix(y_test, y_forest_pred)
print(cm_forest)

cm_tree = confusion_matrix(y_test, y_tree_pred)
print(cm_forest)


#more visual approach
sns.heatmap(cm_forest, annot=True)
plt.xlabel('Predicted label')
plt.ylabel('True label')

print('Accuracy (forest): {:.2f}'.format(sk.metrics.accuracy_score(y_test, y_forest_pred)))
print('Accuracy (tree): {:.2f}'.format(sk.metrics.accuracy_score(y_test, y_tree_pred)))
print('Null Accuracy: {:.2f}'.format(1-(y_train.sum()/(y_train.count()))))


print('Precision (tree): {:.2f}'.format(sk.metrics.precision_score(y_test, y_tree_pred)))
print('Recall (tree): {:.2f}'.format(sk.metrics.recall_score(y_test, y_tree_pred)))

from sklearn.model_selection import cross_val_score

number_of_trees = [50, 100, 150, 200, 250, 300, 350]

for val in number_of_trees:
  scores = cross_val_score(RandomForestClassifier(n_estimators=val), X_train, y_train, cv=5, scoring='accuracy')
  print(scores.mean())

from sklearn.model_selection import GridSearchCV

#define what parameters and what values to vary
parameters = {'max_features': [0.5,0.7,0.9,1.0],
              'n_estimators':list(range(50,200,50)),
              'max_samples':[0.5,0.7,0.9,0.99] }

#build the grid search algorithm
grid_search = GridSearchCV(RandomForestClassifier(), parameters, cv=5, scoring='accuracy') #strattified cross validation when traget is binary or multiclass

#Use training data to perform the nfold cross validation
grid_search.fit(X_train, y_train)

#find the best hyperparameters
print(grid_search.best_params_)
grid_search.best_score_

#1. build an optimized model
forest_classifier_opt = RandomForestClassifier(n_estimators=150,max_samples=0.5, max_features=1)

#2. Fit the model to the data
forest_classifier_opt.fit(X_train, y_train)

#3. make predictions
y_forest_pred_opt = forest_classifier_opt.predict(X_test)

#Measure accuracy
print('Accuracy: {:.2f}'.format(sk.metrics.accuracy_score(y_test, y_forest_pred_opt)))
print('Precision : {:.2f}'.format(sk.metrics.precision_score(y_test, y_forest_pred_opt)))
print('Recall : {:.2f}'.format(sk.metrics.recall_score(y_test, y_forest_pred_opt)))

#calculate a confusion matrix
cm_forest_opt = confusion_matrix(y_test, y_forest_pred_opt)

#Plot the confusion matrix
sns.heatmap(cm_forest_opt, annot=True)
plt.xlabel('Predicted label')
plt.ylabel('True label')

#Try adding other hyperparameters, how much better can you make the model by tuning?
#e.g., min_samples_split (how many points in a node are required to allow a split)
#e.g., max_depth (max depth of each tree)

from sklearn.inspection import permutation_importance

#use permutation importance
perm_result = permutation_importance(forest_classifier_opt, X=X_test, y=y_test, scoring='accuracy', n_repeats=30)

#place values into a dataframe
forest_importances = pd.DataFrame({'variable':X_test.columns,'impo':perm_result.importances_mean.round(4), "sd":perm_result.importances_std.round(4)})

#sort the dataframe
forest_importances.sort_values(by='impo', ascending=False)

#plot the importance
sns.barplot(data=forest_importances, x='variable',y='impo')
plt.xticks(rotation=70)

#plot the importance (switch axis to display labels better?)
sns.barplot(data=forest_importances, y='variable',x='impo')


#1. Create a dataframe
df_question = pd.DataFrame({'Pregnancies':X_train.Pregnancies.mean(),
                            'Glucose':X_train.Glucose.mean(),
                            'BloodPressure':X_train.BloodPressure.mean(),
                            'SkinThickness':X_train.SkinThickness.mean(),
                            'Insulin':X_train.Insulin.mean(),
                            'BMI':X_train.BMI.mean(),
                            'DiabetesPedigreeFunction':X_train.DiabetesPedigreeFunction.mean(),
                            'Age':X_train.Age.mean()},
                             index=[0])
                            

#2. Use the model to make predictions
question_pred =  forest_classifier_opt.predict(df_question)

#3. Take a look at the answer
question_pred

#1. Create a dataframe
df_question = pd.DataFrame({'Pregnancies':X_train.Pregnancies.mean(),
                            'Glucose':list(range(0,200,10)),
                            'BloodPressure':X_train.BloodPressure.mean(),
                            'SkinThickness':X_train.SkinThickness.mean(),
                            'Insulin':X_train.Insulin.mean(),
                            'BMI':X_train.BMI.mean(),
                            'DiabetesPedigreeFunction':X_train.DiabetesPedigreeFunction.mean(),
                            'Age':X_train.Age.mean()})
                            

#2. Use the model to make predictions
question_pred =  forest_classifier_opt.predict(df_question)

#3. Take a look at the answer
question_pred

#add a column to the df_question
df_question['predicted_diabetes'] = question_pred

#plot the predictions
sns.scatterplot(data=df_question, x='Glucose',y='predicted_diabetes')

#load dataset!
