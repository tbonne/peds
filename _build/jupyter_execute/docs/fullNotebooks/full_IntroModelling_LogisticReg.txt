import sklearn as sk
from sklearn.model_selection import train_test_split

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.formula.api as smf


# The tissue sample dataset
df_cancer = pd.read_csv('/content/tissueSamples.csv')

#take a look
df_cancer

df_cancer.dtypes

df_cancer.isna().sum()

sns.displot(data=df_cancer,x='benign')

sns.scatterplot(data=df_cancer, x="benign",y="mean_radius")

#calculate the correlations between each variable
df_cancer_corr = df_cancer.corr()

#plot the correlations in a heat map (hotter = higher correlation)
sns.heatmap(data=df_cancer_corr)

from sklearn.preprocessing import OrdinalEncoder

#get the columns names of features you'd like to turn into 0/1
bin_names = ['benign']

#create a dataframe of those features
bin_features = df_cancer[bin_names]

#fit the scaler to those data
bin_scaler = OrdinalEncoder().fit(bin_features.values)

#use the scaler to transform your data
bin_features = bin_scaler.transform(bin_features.values)

#put these scaled features back into your transformed features dataframe
df_cancer[bin_names] = bin_features

#take a look
df_cancer

bin_scaler.categories_

df_cancer['technician'] = df_cancer.technician.astype('category')


#categorical variables
cat_names = ['technician']

#create dummy variables
df_cat = pd.get_dummies(df_cancer[cat_names])

#add them back to the original dataframe
df_cancer = pd.concat([df_cancer,df_cat], axis=1)

#remove the old columns
df_cancer = df_cancer.drop(cat_names, axis=1)

#take a look
df_cancer

#split the data into training and testing (80/20 split)
df_train, df_test = sk.model_selection.train_test_split(df_cancer, test_size=0.20)


#take a look training dataset
df_train.shape

#take a look
df_test.shape


#Feature Scaling (after spliting the data!)
from sklearn.preprocessing import StandardScaler 

#numeric variables
numb_names = df_train.drop(['benign','technician_1','technician_2','technician_3','technician_4'],axis=1).select_dtypes('number').columns.tolist()

#create the standard scaler object
sc = StandardScaler()

#use this object to fit (i.e., to calculate the mean and sd of each variable in the training data) and then to transform the training data
df_train[numb_names] = sc.fit_transform(df_train[numb_names])

#use the fit from the training data to transform the test data
df_test[numb_names] = sc.transform(df_test[numb_names])


#define model parameters
log_reg = smf.logit('benign ~ mean_symmetry', data=df_train)

#fit the model to the training data
results = log_reg.fit()

#Get a summary of the model parameters
print(results.summary())


#let's first predict values in the testing dataset
df_test['benign_prob'] = results.predict(df_test).round(2)

df_test['benign_pred'] = (df_test['benign_prob']>0.5).astype(int) #here we've used 0.5 as the threshold of benign or not!

df_test

sns.scatterplot(data=df_test,x='mean_symmetry', y='benign')

sns.scatterplot(data=df_test,x='mean_symmetry', y='benign')
sns.scatterplot(data=df_test,x='mean_symmetry', y='benign_pred')

#confusion table
confusion_matrix = sk.metrics.confusion_matrix(df_test['benign'], df_test['benign_pred'])
print(confusion_matrix)

#more visual approach
sns.heatmap(confusion_matrix, annot=True)
plt.xlabel('Predicted label')
plt.ylabel('True label')

print('Accuracy: {:.2f}'.format(sk.metrics.accuracy_score(df_test['benign'], df_test['benign_pred'])))
print('precision: {:.2f}'.format(sk.metrics.precision_score(df_test['benign'], df_test['benign_pred'])))
print('recal: {:.2f}'.format(sk.metrics.recall_score(df_test['benign'], df_test['benign_pred'])))


df_cancer.benign.value_counts()

357/(212+357)

#get all the column names, with a + between them, as a string
all_columns = "+".join(df_train.drop(['benign','technician_1'],axis=1).columns )

#write the formula
my_formula = "benign~" + all_columns

#define model parameters
log_reg2 = smf.logit(my_formula , data=df_train)

#fit the model to the training data
results2 = log_reg2.fit(method='bfgs')

#Get a summary of the model parameters
print(results2.summary())


#let's first predict values in the testing dataset
df_test['benign_prob_multi'] = results2.predict(df_test).round(2)

df_test['benign_pred_multi'] = (df_test['benign_prob_multi']>0.5).astype(int) #here we've used 0.5 as the threshold of benign or not!

df_test

#confusion table
confusion_matrix2 = sk.metrics.confusion_matrix(df_test['benign'], df_test['benign_pred_multi'])
print(confusion_matrix2)

#more visual approach
sns.heatmap(confusion_matrix2, annot=True)
plt.xlabel('Predicted label')
plt.ylabel('True label')

print('Accuracy: {:.2f}'.format(sk.metrics.accuracy_score(df_test['benign'], df_test['benign_pred_multi'])))
print('Precision: {:.2f}'.format(sk.metrics.precision_score(df_test['benign'], df_test['benign_pred_multi'])))
print('Recall: {:.2f}'.format(sk.metrics.recall_score(df_test['benign'], df_test['benign_pred_multi'])))

df_titanic = pd.read_csv('titanic_subset.csv')

df_titanic.head(5)

df_titanic.describe()

df_titanic.isna().sum() / len(df_titanic)

#Is pclass a ordinal variable... if so, how many data points in each class.
df_titanic.Pclass.value_counts()

df_titanic.Embarked.value_counts()

#what does the distribution of ages look like?
df_titanic.Age_wiki.hist()

#is fare numeric, if so what does its distribution look like?
df_titanic.Fare.hist()

#let's only work with data where we have a value for the target variable: survived or not

#filter out missing survival data
df_titanic_survived = df_titanic[df_titanic.Survived.isna()==False]

#check to make sure all worked
df_titanic_survived.isna().sum() / len(df_titanic_survived)

#Is age related to 
sns.violinplot(data=df_titanic_survived, x='Survived', y='Age_wiki')

sns.barplot(data=df_titanic_survived, y='Survived', x='Pclass')

#convert Pclass to category
df_titanic_survived['Pclass'] = df_titanic_survived.Pclass.astype('category')

#categorical variables
cat_names = ['Pclass','Embarked']

#create dummy variables
df_cat = pd.get_dummies(df_titanic_survived[cat_names])

#add them back to the original dataframe
df_titanic_survived = pd.concat([df_titanic_survived,df_cat], axis=1)

#remove the old columns
df_titanic_survived = df_titanic_survived.drop(cat_names, axis=1)

#take a look
df_titanic_survived.head(3)


from sklearn.preprocessing import OrdinalEncoder

#get the columns names of features you'd like to turn into 0/1
bin_names = ['Sex']

#create a dataframe of those features
bin_features = df_titanic_survived[bin_names]

#fit the scaler to those data
bin_scaler = OrdinalEncoder().fit(bin_features.values)

#use the scaler to transform your data
bin_features = bin_scaler.transform(bin_features.values)

#put these scaled features back into your transformed features dataframe
df_titanic_survived[bin_names] = bin_features

#take a look
df_titanic_survived.head(3)

#split the data into training and testing (80/20 split)
df_train, df_test = sk.model_selection.train_test_split(df_titanic_survived, test_size=0.20)

#Feature Scaling (after spliting the data!)
from sklearn.preprocessing import StandardScaler 

#numeric variables
numb_names = ['Age_wiki','Fare','SibSp','Parch']

#create the standard scaler object
sc = StandardScaler()

#use this object to fit (i.e., to calculate the mean and sd of each variable in the training data) and then to transform the training data
df_train[numb_names] = sc.fit_transform(df_train[numb_names])

#use the fit from the training data to transform the test data
df_test[numb_names] = sc.transform(df_test[numb_names])

#define model parameters
log_reg_sur = smf.logit('Survived ~ Age_wiki + Fare + SibSp + Parch + Pclass_1 + Pclass_2 + Embarked_Q + Embarked_S', data=df_train)

#fit the model to the training data
results_sur = log_reg_sur.fit()

#Get a summary of the model parameters
print(results_sur.summary())

#let's first predict values in the testing dataset
df_test['survive_prob'] = results_sur.predict(df_test).round(2)

df_test['survive_pred'] = (df_test['survive_prob']>0.5).astype(int) #here we've used 0.5 as the threshold of benign or not!

df_test.head(3)

confusion_matrix_sur = sk.metrics.confusion_matrix(df_test['Survived'], df_test['survive_pred'])
sns.heatmap(confusion_matrix_sur, annot=True)
plt.xlabel('Predicted label')
plt.ylabel('True label')


print('Accuracy: {:.2f}'.format(sk.metrics.accuracy_score(df_test['Survived'], df_test['survive_pred'])))
print('Precision: {:.2f}'.format(sk.metrics.precision_score(df_test['Survived'], df_test['survive_pred'])))
print('Recall: {:.2f}'.format(sk.metrics.recall_score(df_test['Survived'], df_test['survive_pred'])))

#load the 'new' data 

#use your model to make predictions

#measure the performace of your model (did it correctly predict the new data?)
