{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbonne/peds/blob/main/docs/introComm/A_B_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_cCZ26oC09s"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/tbonne/peds/main/images/best-mobile-games.jpg\" width=\"500\" alt=\"colab\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AblYbIauo2us"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQpnBRMDe_mB"
      },
      "source": [
        "## <font color='darkorange'>A/B Testing</font>\n",
        "\n",
        "Here we will look at how to collect and analyze data to determine the difference between two groups. The idea here is that if we randomly assign individuals to two groups we end up with comparable groups. If we then measure how these two groups respond to a treatment (e.g., being given game version A vs. game version B) we can better determine the effect of that treatment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFmN1aLjfVej"
      },
      "source": [
        "We'll take a look at data collected to test how effective different versions of a game are at retaining users.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6oL7k7uftq4"
      },
      "outputs": [],
      "source": [
        "#load packages\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ7MxOMHflXV"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5NHlsf8GeMWW",
        "outputId": "ac52c3a7-5bba-4bdc-e92b-b734062b339d"
      },
      "outputs": [],
      "source": [
        "#load data\n",
        "df_cats = pd.read_csv(\"/content/cookie_cats.csv\")\n",
        "\n",
        "#take a look\n",
        "df_cats.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfKCZZ6mL0Fj"
      },
      "source": [
        "### <font color='darkorange'>Describe the data</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XSKxhqkFsDY"
      },
      "source": [
        "How many in each group?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "PB_UE20MFuEK",
        "outputId": "f647ac06-7319-417d-9607-cafef1b772ff"
      },
      "outputs": [],
      "source": [
        "df_cats.version.?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqhZStXAFzfZ"
      },
      "source": [
        "How many users returned after 7 days?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "fcRRUsKgF4XF",
        "outputId": "b55a4a17-9857-4316-c2a1-35ba7e8c6de4"
      },
      "outputs": [],
      "source": [
        "#gate placed at level 30\n",
        "df_cats.groupby(\"?\")[\"?\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovWxCFQkiTn"
      },
      "source": [
        "### <font color='darkorange'>Visualize the data</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Lm36a2uZmIW5",
        "outputId": "f0da7420-2b99-4eb4-8a99-2f3100dd1b5e"
      },
      "outputs": [],
      "source": [
        "#plot the differences between the versions\n",
        "sns.barplot(?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKdW7X6B0epK"
      },
      "source": [
        "### <font color='darkorange'>Wrangle the data</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOHxEi5y0xLo"
      },
      "source": [
        "Convert the binary traget and binary input variable to 0/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "u9RspDuUpif0",
        "outputId": "cf5cfe5e-6680-40ea-84e4-aea61cbcd094"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#build the encoder\n",
        "le_retention7 = LabelEncoder()\n",
        "le_version = LabelEncoder()\n",
        "\n",
        "#fit and transform the gender column\n",
        "df_cats['retention_7'] = le_retention7.fit_transform(df_cats['retention_7'])\n",
        "df_cats['version'] = le_version.fit_transform(df_cats['version'])\n",
        "\n",
        "#take a look\n",
        "df_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r2PCkOXxtAt",
        "outputId": "cff03c4d-c1f4-44db-c41b-db4f1a40908e"
      },
      "outputs": [],
      "source": [
        "le_retention7.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FdoARXCxyD6",
        "outputId": "54886e05-529e-41a6-d840-b9db555fb628"
      },
      "outputs": [],
      "source": [
        "le_version.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oZGMz1Y7G79"
      },
      "source": [
        "Split your data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uuaVICoRlMs"
      },
      "outputs": [],
      "source": [
        "#split data into predictors (X) and target (y)\n",
        "X = df_cats.drop(['retention_7','retention_1','userid','sum_gamerounds'], axis=1)\n",
        "y = df_cats['retention_7']\n",
        "\n",
        "#split these data into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAk0s-hKmH7i"
      },
      "source": [
        "### <font color='darkorange'>Build a model</font>\n",
        "\n",
        "Can we predict which game version does better?\n",
        "\n",
        "* Note: given the large class imbalance let's make the model more sensitive to errors in the minority class. So, as class 1 (i.e., making it to 7 days) is rare, errors in predicting class 1 will \"hurt\" the model more. It does this by changing the loss function (something we have not covered in this class but you will be seeing more of in later classes!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "eHrG5Z1lRJ5q",
        "outputId": "d2e5b4e7-86d7-406c-dc17-f30e40fbdc3e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#1. build the algorithm\n",
        "classifier = RandomForestClassifier(class_weight=\"balanced\")\n",
        "\n",
        "#2. fit the algorithm to the data\n",
        "classifier.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HTaTSRe3-uS"
      },
      "source": [
        "Check how your model does on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "zwf5yjwR3-dU",
        "outputId": "47d469f1-8f89-4c0d-9ec8-fe64e2843e15"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#predict on testing data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "#create a confusion matrix\n",
        "cm_logit = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#visualize the confusion matrix\n",
        "sns.heatmap(cm_logit, annot=True)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifpEQF3856_Z",
        "outputId": "a5abd598-bb3a-49aa-8eba-796852127cba"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "model_acc = accuracy_score(y_test, y_pred)\n",
        "model_prec = precision_score(y_test, y_pred)\n",
        "model_rec = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"accuracy: {model_acc:.2f}\" )\n",
        "print(f\"precision: {model_prec:.2f}\" )\n",
        "print(f\"recall: {model_rec:.2f}\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bkodZqL52rQ"
      },
      "source": [
        "Not great! This suggests that the version a user is playing is not likely to have a big impact on wether they play for more than 7 days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='darkorange'>Estimate the effect of version</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGPMT5A6HvaA"
      },
      "source": [
        "Let's estimate how the model thinks the probability of making it to more than 7 days is impacted by the version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5bi1EKuyqmn",
        "outputId": "facca2a7-9e4d-4bdc-e078-968a8a98897f"
      },
      "outputs": [],
      "source": [
        "#1. Create a dataframe\n",
        "df_question = pd.DataFrame({'version':[0,1]})\n",
        "\n",
        "#2. Use the model to make predictions\n",
        "question_pred =  classifier.predict_proba(df_question)\n",
        "\n",
        "#3. Take a look at the answer\n",
        "question_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQERV1-9wD7"
      },
      "source": [
        "Now we can calculate the difference in probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1d7Pr1895kq",
        "outputId": "d4e76ae0-e21a-42df-ab91-56018a659903"
      },
      "outputs": [],
      "source": [
        "question_pred[0,1] - question_pred[1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3aEQrBY96q0"
      },
      "source": [
        "This is known as the average treatment effect, i.e., how much does the treatment (versions) impact the outcome on average."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ebJzc2C-Daq"
      },
      "source": [
        "As a final step, if presenting this information to someone, it's a good idea to quantify an estimate of the uncertainty around the effect. Let's do that below with a bootstrapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EpmJUrspvHaG",
        "outputId": "5ea4f8f8-af86-4da2-9cae-a5f1746b66e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "\n",
        "n_bootstraps = 30\n",
        "ates = []\n",
        "\n",
        "for _ in range(n_bootstraps):\n",
        "    # resample data\n",
        "    X_b, y_b = resample(X_train, y_train, replace=True)\n",
        "    clf = RandomForestClassifier().fit(X_b, y_b)\n",
        "\n",
        "    # predict prob for version=0 and version=1\n",
        "    df_question = pd.DataFrame({'version':[0,1]})\n",
        "    probs = clf.predict_proba(df_question)\n",
        "    ate = probs[1,1] - probs[0,1]\n",
        "    ates.append(ate)\n",
        "\n",
        "sns.histplot(ates)\n",
        "plt.xlabel(\"ATE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdet_Ulj7XvC"
      },
      "source": [
        "The histogram shows us the distribution of average treatment effects. Let's summarize this distribution to make it easier to communicate. Let's get the mean and the confidence intervals of the estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSvkypBp7YDS",
        "outputId": "01e82228-62eb-4a0c-9eb2-0f454c558ed0"
      },
      "outputs": [],
      "source": [
        "print(f\"ATE: {np.mean(ates):.3f}\")\n",
        "\n",
        "ci_lower, ci_upper = np.percentile(ates, [2.5, 97.5])\n",
        "print(f\"ATE 95% CI: ({ci_lower:.3f}, {ci_upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj8wB-Xt8Z1F"
      },
      "source": [
        "<p align=\"left\">\n",
        "  <img src=\"https://raw.githubusercontent.com/tbonne/peds/main/images/take_action.jpg\" width=\"100\" alt=\"colab\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuaEe9OhJayk"
      },
      "source": [
        "> Try redoing the exercise above without the increased penalty for the minority class: e.g., remove class_weight=\"balanced\". How do the results change?\n",
        "\n",
        "> If time permits, try redoing the exercise with sum_game_rounds instead of retention_7 as the outcome variable. Do you come to the same conclusion about which version is better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNOUHRuV45oP"
      },
      "source": [
        "### <font color='darkorange'>Bonus</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBIX1sSM_EFI"
      },
      "source": [
        "> Try redoing the exercise above with a linear regression approach. You can use a scikit-learn LinearRegression or you can use smf which gives more statistical outputs.\n",
        "\n",
        "> How do the results differ or remain the same?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDGv4A6e_Dji"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm #for running regression!\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "#split these data into training and testing datasets\n",
        "# for smf we need to have retention_7 and version in a data frame\n",
        "df_cats_train, df_cats_test = train_test_split(df_cats, test_size=0.20, stratify=df_cats['retention_7'])\n",
        "\n",
        "#1. Build the model\n",
        "linear_reg_model = smf.logit(formula='retention_7 ~ version ', data=df_cats_train)\n",
        "\n",
        "#2. Use the data to fit the model (i.e., find the best intercept and slope parameters)\n",
        "result = linear_reg_model.fit()\n",
        "\n",
        "#3. take a look at the summary\n",
        "result.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJqFrYyyYzMx"
      },
      "source": [
        "### <font color='darkorange'>Further reading</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym_r6d4Wo2uz"
      },
      "source": [
        "> If you would like the notebook without missing code check out the [full code](https://colab.research.google.com/github/tbonne/peds/blob/main/docs/fullNotebooks/full_A_B_Testing.ipynb) version."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "A_B_Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
