
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering algorithms &#8212; Practical exercises in data science - PEDS</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/runners_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Practical exercises in data science - PEDS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Introduction to PEDS
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 1 - Coding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroColab.html">
   1.
   <font color="darkorange">
    Let’s start coding
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroNotebooks.html">
   2.
   <font color="darkorange">
    Colaboratory notebooks!
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroPython.html">
   3.
   <font color="darkorange">
    Short introduction to Python
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroNumpy.html">
   4.
   <font color="darkorange">
    Introduction to Numpy
   </font>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 2 - Data Wrangling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroDataFrames.html">
   5.
   <font color="darkorange">
    Working with data
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introData/IntroData1_DataFrames.html">
   6.
   <font color="darkorange">
    Introduction to DataFrames
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introData/IntroData2_LoadingData.html">
   7.
   <font color="darkorange">
    Using existing data
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introData/IntroData3_MissingData.html">
   8.
   <font color="darkorange">
    Missing Data
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introData/IntroData4_groupby.html">
   9.
   <font color="darkorange">
    Grouping data
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introData/IntroData5_CombineData.html">
   10.
   <font color="darkorange">
    Combining data
   </font>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 3 - Exploritory Data Analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroViz.html">
   11.
   <font color="darkorange">
    Let’s start exploring
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introViz/introViz1_histograms.html">
   12.
   <font color="darkorange">
    Summary statistics and histograms
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introViz/introViz2_densityPlots.html">
   13.
   <font color="darkorange">
    Density plots and normal distributions
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introViz/IntroViz3_scatterplots.html">
   14.
   <font color="darkorange">
    Scatter plots
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introViz/IntroClustering1_kmeans_HDBScan.html">
   15.
   <font color="darkorange">
    Clustering algorithms
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introViz/IntroClustering2_highDimensions.html">
   16.
   <font color="darkorange">
    Clustering in higher dimensions
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dataChallenges/DataChallenge1.html">
   17.
   <font color="darkorange">
    Class Data Challenge 1
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Projects/Project1_ExploritoryDataAnalysis.html">
   18.
   <font color="darkorange">
    Project 1 - Exploratory Data Analysis
   </font>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 4 - Building models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroModeling.html">
   19.
   <font color="darkorange">
    Let’s build some models!
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introModeling/IntroModeling1_LinearReg.html">
   20.
   <font color="darkorange">
    Linear regression
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introModeling/IntroModelling_LogisticReg.html">
   21.
   <font color="darkorange">
    Logistic regression
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introModeling/IntroModeling3_decisionTrees.html">
   22.
   <font color="darkorange">
    Decision trees
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introModeling/Intro_RandomForest.html">
   23.
   <font color="darkorange">
    Random forests
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dataChallenges/DataChallenge2.html">
   24.
   <font color="darkorange">
    Class Data Challenge II
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Projects/Project2_MakingPredictions.html">
   25.
   <font color="darkorange">
    Project 2 - Making Predictions
   </font>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 5 - Interpreting and communicating models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../IntroComm.html">
   26.
   <font color="darkorange">
    Let’s try to learn from our models
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introComm/IntroCausalAnalysis.html">
   27.
   <font color="darkorange">
    Explainability vs Causality
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introComm/A_B_Testing.html">
   28.
   <font color="darkorange">
    A/B Testing
   </font>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Projects/Project3_AnsweringQuestions.html">
   29.
   <font color="darkorange">
    Project 3 - Answering Questions
   </font>
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/docs/fullNotebooks/full_IntroClustering1_kmeans_HDBScan.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fdocs/fullNotebooks/full_IntroClustering1_kmeans_HDBScan.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/docs/fullNotebooks/full_IntroClustering1_kmeans_HDBScan.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-simulating-data-font">
   <font color="darkorange">
    Simulating data
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-k-means-font">
   <font color="darkorange">
    K-Means
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-tuning-machine-learning-algorithms-font">
   <font color="darkorange">
    Tuning machine learning algorithms
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-make-our-own-functions-font">
   <font color="darkorange">
    Make our own functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-using-loops-font">
   <font color="darkorange">
    Using loops
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-hdbscan-font">
   <font color="darkorange">
    HDBscan
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   <font color="darkorange">
    Make our own functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-running-loops-font">
   <font color="darkorange">
    Running loops
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-bonus-font">
   <font color="darkorange">
    Bonus
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-further-reading-font">
   <font color="darkorange">
    Further reading
   </font>
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><font color='darkorange'>Clustering algorithms</font></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-simulating-data-font">
   <font color="darkorange">
    Simulating data
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-k-means-font">
   <font color="darkorange">
    K-Means
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-tuning-machine-learning-algorithms-font">
   <font color="darkorange">
    Tuning machine learning algorithms
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-make-our-own-functions-font">
   <font color="darkorange">
    Make our own functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-using-loops-font">
   <font color="darkorange">
    Using loops
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-hdbscan-font">
   <font color="darkorange">
    HDBscan
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   <font color="darkorange">
    Make our own functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-running-loops-font">
   <font color="darkorange">
    Running loops
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-bonus-font">
   <font color="darkorange">
    Bonus
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-darkorange-further-reading-font">
   <font color="darkorange">
    Further reading
   </font>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/tbonne/IntroDataScience/blob/main/InClassNotebooks/IntroClustering1_kmeans_HDBScan.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<img src='http://drive.google.com/uc?export=view&id=1eaZWfBLfmkzNndnA8pJvo6tO4Lm7Qz83' width=500><hr class="docutils" />
<div class="section" id="font-color-darkorange-clustering-algorithms-font">
<h1><font color='darkorange'>Clustering algorithms</font><a class="headerlink" href="#font-color-darkorange-clustering-algorithms-font" title="Permalink to this headline">¶</a></h1>
<p>We will look at developing skills to detect clusters in your data. Identifying clusters can be very helpful when exploring your data, and is a form of unsupervised machine learning.</p>
<blockquote>
<div><p>To perform clustering we will make use of the <strong>sklearn</strong> library. This library is a very useful machine learning library in python. We’ll use this library a lot in this course!</p>
</div></blockquote>
<p>There is no single best clustering algorithm, as it will often depend on the data you have and the question you’d like to address. In this exercise we will look at two good clustering algorithms.</p>
<ul class="simple">
<li><p>K-means</p></li>
<li><p>Hdbscan</p></li>
</ul>
<p>Load python libraries</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="nn">sk</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cluster</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="font-color-darkorange-simulating-data-font">
<h2><font color='darkorange'>Simulating data</font><a class="headerlink" href="#font-color-darkorange-simulating-data-font" title="Permalink to this headline">¶</a></h2>
<p>Simulating data is a great way to test out different machine learning algorithms. Here we’ll use the numpy library to create some random numbers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#simulate 100 values from a normal distribution with a mean of 1 and an sd of 4</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1">#take a look</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s simulate some data where we know how many clusters there are.</p>
<blockquote>
<div><p>First let’s create 1000 points and set them to class 1. Each point will get a random x and y coordinate.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#simulate some random values</span>
<span class="n">array_class1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="c1">#put them in a dataframe</span>
<span class="n">df_class1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">array_class1</span><span class="p">)</span>

<span class="c1">#plot it</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_class1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>

</pre></div>
</div>
</div>
</div>
<p>Create another set of 1000 points and assign them to class 2. Then we’ll add the two sets of points together by using <strong>concat</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#generate some random values</span>
<span class="n">array_class2</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

<span class="c1">#put them in a dataframe</span>
<span class="n">df_class2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">array_class2</span><span class="p">)</span>

<span class="c1">#bind the two dataframes together by rows</span>
<span class="n">df_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_class1</span><span class="p">,</span><span class="n">df_class2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1">#axis=0 just says to bind by rows, axis=1 would be by columns </span>

<span class="c1">#plot it</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_class</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="font-color-darkorange-k-means-font">
<h2><font color='darkorange'>K-Means</font><a class="headerlink" href="#font-color-darkorange-k-means-font" title="Permalink to this headline">¶</a></h2>
<p>Let’s try out the first classification algorithm: k-means.</p>
<blockquote>
<div><p>Sklearn uses a standard approach to machine learning models. We’ll go through each step with k-means.</p>
</div></blockquote>
<p><strong>First</strong> let’s build the machine learning algorithm that we will use (i.e., k-means)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#initalize the kmeans algorithm</span>
<span class="n">clus_kmeans</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p><strong>Second</strong> let’s fit the model using data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#fit the model</span>
<span class="n">clus_kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Third</strong>, now that the model is built and fit to data we can use it to make predictions!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#make some predictions</span>
<span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_kmeans&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clus_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>

<span class="c1">#take a look</span>
<span class="n">df_class</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Finaly</strong>, we can visualize the predictions it made by using seaborn</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#plot it!</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_class</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;pred_kmeans&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is what is considered as a hard clustering algorithm - it assigns every point to a cluster. It also makes some assumptions about clusters:</p>
<ul class="simple">
<li><p>You know in advance how many clusters there are</p></li>
<li><p>Clusters are roughly oval shaped (noramlly distributied along each dimension)</p></li>
</ul>
<img src='http://drive.google.com/uc?export=view&id=1WC4tXGCEF-1_2LQ74gIxJAZ-GLXCwBdK' width="100" align = 'left'>  <p>Go back and try shifting the mean and standard deviation of the simulated clusters and see how well k-means does. Try changing the number of clusters k-means looks for. When does it break down?</p>
<img src='http://drive.google.com/uc?export=view&id=1qWrKY9TgpgQaBCzZfz1xLTV6iCeSwfmG' width="100" align = 'left'></div>
<div class="section" id="font-color-darkorange-tuning-machine-learning-algorithms-font">
<h2><font color='darkorange'>Tuning machine learning algorithms</font><a class="headerlink" href="#font-color-darkorange-tuning-machine-learning-algorithms-font" title="Permalink to this headline">¶</a></h2>
<p>The elbow method can be used to help choose how many clusters are likely in the data. It also introduces us to how tune machine learning algorithms by running the model using different parameters and monitoring how well the algorithm performs.</p>
<p>First let’s measure how successfull the clustering algorithm is. There are many ways to measure <em>success</em> in clustering, but here we will use <em>mean silhouette distance</em>. Which describes how far apart the points within clusters are from each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Mean silhouette distance</span>
<span class="n">sk</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">df_class</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span><span class="n">labels</span><span class="o">=</span><span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_kmeans&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Try the model above with a different number of clusters and see how this mean silhouette value changes. At what number of clusters is the mean silhouette distance the largest (large means more seperation between clusters).</p>
<blockquote>
<div><p>e.g., is the true number of clusters the highest?</p>
</div></blockquote>
</div>
<div class="section" id="font-color-darkorange-make-our-own-functions-font">
<h2><font color='darkorange'>Make our own functions</font><a class="headerlink" href="#font-color-darkorange-make-our-own-functions-font" title="Permalink to this headline">¶</a></h2>
<p>Note: here we are changing a parameter and re-running the code. In cases like these it can be sometimes useful to create our own functions. Let’s take a look at how to create a function in python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#here is a simple function</span>
<span class="k">def</span> <span class="nf">run_k_means</span><span class="p">(</span><span class="n">numb</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">numb</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we’ve created it let’s use it</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">run_k_means</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This function just takes one input (numb) and then prints that number.</p>
<p>Let’s add each of the model steps above inside the function, with the goal of printing the average silhouette distance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_k_means</span><span class="p">(</span><span class="n">numb</span><span class="p">):</span>
  
  <span class="c1">#1. initalize the ml algorithm</span>
  <span class="n">clus_kmeans</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">numb</span><span class="p">)</span>

  <span class="c1">#2. fit the ml algorithm</span>
  <span class="n">clus_kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>

  <span class="c1">#3. make some predictions</span>
  <span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_kmeans&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clus_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>

  <span class="c1">#4. measure performance</span>
  <span class="n">avg_sil</span> <span class="o">=</span> <span class="n">sk</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">df_class</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span><span class="n">labels</span><span class="o">=</span><span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_kmeans&#39;</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">avg_sil</span>
</pre></div>
</div>
</div>
</div>
<p>Notice here that the input (numb) is now used to build a kmeans model with n_clusters = numb</p>
<p>Let’s use this new function and see how it works!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">run_k_means</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Is it much easier to figure out what number of clusters results in the highest avgerage silhouette score?</p>
</div>
<div class="section" id="font-color-darkorange-using-loops-font">
<h2><font color='darkorange'>Using loops</font><a class="headerlink" href="#font-color-darkorange-using-loops-font" title="Permalink to this headline">¶</a></h2>
<p>One last coding trick we’ll learn today, is how to use a loop to make this even easier.</p>
<p>Let’s first look at how loops work in python</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we know the basic structure of a loop, and what it can do, let’s use it to help figure out what number of clusters is optimal!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">run_k_means</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s plot this out! To store the silhouette values as we run the loop, we’ll create an empty list (avg_sil) and each run in the loop we’ll add the average silhouette value to the list using <strong>append</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">avg_sil</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">avg_sil</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">run_k_means</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have a list of average silhouette values, let’s place these values in a <strong>dataframe</strong> and plot them using <strong>seaborn</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#create a dictionary</span>
<span class="n">dict_sil</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;sil&#39;</span><span class="p">:</span><span class="n">avg_sil</span><span class="p">,</span> <span class="s1">&#39;clusters&#39;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> <span class="p">}</span>

<span class="c1">#convert the dictionary into a dataframe</span>
<span class="n">df_sil</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dict_sil</span><span class="p">)</span>

<span class="c1">#plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;clusters&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;sil&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_sil</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<img src='http://drive.google.com/uc?export=view&id=1qWrKY9TgpgQaBCzZfz1xLTV6iCeSwfmG' width="100" align = 'left'></div>
<div class="section" id="font-color-darkorange-hdbscan-font">
<h2><font color='darkorange'>HDBscan</font><a class="headerlink" href="#font-color-darkorange-hdbscan-font" title="Permalink to this headline">¶</a></h2>
<p>Ok let’s see how another algorithm does: hdbscan. This method is newer than k-means and focuses on the finding high density regions surrounded by low density.</p>
<p>To run this clustering algorithm we need to install another python library. Up until now we’ve been using the libraries on colab, but now we’d like to use one that is not already installed. To do this we install it manually using the !pip command. Then import it just like any other library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install hdbscan
import hdbscan
</pre></div>
</div>
</div>
</div>
<p>Now we can use the <strong>hdbscan</strong> clustering method, it will follow the same steps as sklearn.</p>
<p>First initalize the ml algorithm</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#initalize the kmeans algorithm (hyperparameter - choose minimum cluster size)</span>
<span class="n">clus_hdbscan</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span> <span class="o">=</span> <span class="mi">30</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>Second fit the ml algorithm to the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#fit the model</span>
<span class="n">clus_hdbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Third use the ml algorithm to make some predictions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#make some predictions</span>
<span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clus_hdbscan</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, visualize the predictions of the ml algorithm</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#plot it!</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_class</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice the negative class? This is HDBscans way of saying that it isn’t sure about those points. It is a soft clustering algorithm in that it will give you the probability of each point belonging to a class.</p>
<p>We can now measure the mean silhouette distance for HDBscan clustering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#estimate silhouette score for k-means</span>
<span class="n">sk</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">df_class</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]],</span> <span class="n">labels</span><span class="o">=</span><span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#get only those points that are given a cluster</span>
<span class="n">df_class_sub</span> <span class="o">=</span> <span class="n">df_class</span><span class="p">[</span><span class="n">df_class</span><span class="o">.</span><span class="n">pred_khdbscan</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1">#estimate silhouette score for k-means</span>
<span class="n">sk</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">df_class_sub</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]],</span><span class="n">labels</span><span class="o">=</span><span class="n">df_class_sub</span><span class="p">[</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>How does it do compared to k-means? Does that compare with what you see visually?</p>
</div>
<div class="section" id="id1">
<h2><font color='darkorange'>Make our own functions</font><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<img src='http://drive.google.com/uc?export=view&id=1WC4tXGCEF-1_2LQ74gIxJAZ-GLXCwBdK' width="100" align = 'left'>  <p>Let’s try to make another function just like the one we did for the k-means algorithm.</p>
<blockquote>
<div><p>feel free to copy and paste the steps from above
remember to think carefully about where the input <strong>minNumb</strong> will go in the code.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_HDBScan</span><span class="p">(</span><span class="n">minNumb</span><span class="p">):</span>
  
  <span class="c1">#1. initalize the ml algorithm</span>
  <span class="n">clus_hdbscan</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span> <span class="o">=</span> <span class="n">minNumb</span><span class="p">)</span> 

  <span class="c1">#2. fit the ml algorithm</span>
  <span class="n">clus_hdbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>

  <span class="c1">#3. make some predictions</span>
  <span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clus_hdbscan</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df_class</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span> <span class="p">)</span>

  <span class="c1">#4. measure performance</span>
  <span class="n">avg_sil</span> <span class="o">=</span> <span class="n">sk</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">df_class</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]],</span> <span class="n">labels</span><span class="o">=</span><span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;pred_khdbscan&#39;</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">avg_sil</span>
</pre></div>
</div>
</div>
</div>
<p>Try out you new function and see if it works!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#run your function with 500 as the minimum number of points</span>
<span class="n">run_HDBScan</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="font-color-darkorange-running-loops-font">
<h2><font color='darkorange'>Running loops</font><a class="headerlink" href="#font-color-darkorange-running-loops-font" title="Permalink to this headline">¶</a></h2>
<img src='http://drive.google.com/uc?export=view&id=1WC4tXGCEF-1_2LQ74gIxJAZ-GLXCwBdK' width="100" align = 'left'>  <p>Let’s try and use a loop to try out a bunch of different values for the minimum number of points parameter.</p>
<blockquote>
<div><p>the <strong>range()</strong> function follows range(from,to,by) format. e.g., range(10,70,10) = 10, 20, 30, 40, 50, 60</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">run_HDBScan</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="font-color-darkorange-bonus-font">
<h2><font color='darkorange'>Bonus</font><a class="headerlink" href="#font-color-darkorange-bonus-font" title="Permalink to this headline">¶</a></h2>
<p>If all is going well, you might want to try to plot the results!</p>
<blockquote>
<div><p>You can follow along with how we ploted the results from the k-means.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">avg_sil_hd</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">avg_sil_hd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">run_HDBScan</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#create a dictionary</span>
<span class="n">dict_sil</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;sil&#39;</span><span class="p">:</span><span class="n">avg_sil_hd</span><span class="p">,</span> <span class="s1">&#39;min_cluster_size&#39;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> <span class="p">}</span>

<span class="c1">#convert the dictionary into a dataframe</span>
<span class="n">df_sil_hd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dict_sil</span><span class="p">)</span>

<span class="c1">#plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;min_cluster_size&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;sil&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dict_sil</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Can you find an optimum value for min_cluster_size? If you go back and run the HDBScan algorithm with the optimal min_cluster_size do you see large differences in how it clusters the data?</p>
<p>Finally, what happends if you run your function for large min_cluster sizes? How large can you go before your code fails, and why do you think it failed?</p>
</div>
<div class="section" id="font-color-darkorange-further-reading-font">
<h2><font color='darkorange'>Further reading</font><a class="headerlink" href="#font-color-darkorange-further-reading-font" title="Permalink to this headline">¶</a></h2>
<p>A more detailed look at <a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html">HDBScan</a>.</p>
<p>A comparison between a number of different <a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html">clustering algorithms</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/fullNotebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tyler R. Bonnell<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>